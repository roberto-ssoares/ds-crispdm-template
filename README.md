![Banner](.figures/banner.png)

# ğŸ§  Roberto DS Framework (RDSF)

### Professional CRISP-DM Data Science Architecture Template

![CRISP-DM](https://img.shields.io/badge/Methodology-CRISP--DM-blue)
![Reproducible](https://img.shields.io/badge/Reproducible-Yes-brightgreen)
![uv-powered](https://img.shields.io/badge/Environment-uv-purple)
![Python](https://img.shields.io/badge/Python-3.12+-blue)
![Status](https://img.shields.io/badge/Status-Active-success)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

![RDSF](https://img.shields.io/badge/Framework-Roberto%20DS%20Framework-black)

---

## ğŸ¯ PropÃ³sito

Este repositÃ³rio Ã© um **template estruturado para projetos de CiÃªncia de Dados**, combinando:

- Framework **CRISP-DM**

- OrganizaÃ§Ã£o em camadas **Raw â†’ Bronze â†’ Silver â†’ Gold**

- SeparaÃ§Ã£o clara entre:
  
  - Dados
  
  - Notebooks
  
  - CÃ³digo fonte (`src/`)
  
  - Modelos
  
  - Artefatos
  
  - SubmissÃµes

O objetivo Ã© permitir:

- Reprodutibilidade

- EvoluÃ§Ã£o progressiva (Notebook â†’ src/)

- OrganizaÃ§Ã£o profissional

- Narrativa clara para portfÃ³lio e ambientes corporativos

---

# ğŸ§  Filosofia do Template

Este template segue trÃªs princÃ­pios:

### 1ï¸âƒ£ MÃ©todo antes de cÃ³digo

Cada projeto Ã© guiado por CRISP-DM, com notebooks organizados por fase.

### 2ï¸âƒ£ Artefatos explÃ­citos

Cada fase gera outputs documentados que alimentam a prÃ³xima etapa.

### 3ï¸âƒ£ EvoluÃ§Ã£o progressiva

O projeto pode comeÃ§ar simples (notebook-only) e evoluir para estrutura profissional com `src/`.

---

# ğŸ“‚ Estrutura do Projeto

```text
00_data/
  00_raw/
  01_bronze/
  02_silver/
  03_gold/

01_skills/
  (instruÃ§Ãµes CRISP-DM em .md)

02_notebooks/
  00_project_index.ipynb
  01_business_data_understanding.ipynb
  02_data_preparation_abt.ipynb
  03_modeling_validation.ipynb
  04_operationalization_submission.ipynb

03_src/
  (cÃ³digo reutilizÃ¡vel â€“ opcional no inÃ­cio)

04_models/
  best_model.pkl

05_artifacts/
  00_config/params.json
  01/
  02/
  03/
  04/

06_submissions/
  submission.csv
```

---

## ğŸ§± Arquitetura Conceitual

Este template organiza um projeto de CiÃªncia de Dados como um **fluxo CRISP-DM com contratos de artefatos**, permitindo reprodutibilidade e evoluÃ§Ã£o progressiva (Notebook â†’ `src/`).

### VisÃ£o em Camadas (Dados)

- **00_raw**: dados originais, sem alteraÃ§Ãµes (fonte)
- **01_bronze**: ingestÃ£o e padronizaÃ§Ã£o mÃ­nima (tipos/colunas)
- **02_silver**: dados limpos, consistentes, prontos para anÃ¡lise
- **03_gold**: **ABT** (Analytical Base Table) / dataset final de modelagem

### VisÃ£o em Fases (CRISP-DM)

- **Notebook 01**: Business + Data Understanding (EDA + Qualidade)
- **Notebook 02**: Data Preparation (Feature Engineering + ABT)
- **Notebook 03**: Modeling + Validation (CV + GridSearch + decisÃ£o)
- **Notebook 04**: Operationalization (modelo salvo + inferÃªncia + submission)

### Contratos de Artefatos

Cada fase produz **outputs explÃ­citos** em `05_artifacts/` (e/ou `03_gold`) que alimentam a fase seguinte.  
Isso reduz retrabalho, evita divergÃªncias e facilita auditoria do processo.

> **EvoluÃ§Ã£o progressiva:** no inÃ­cio, a lÃ³gica pode viver nos notebooks. Com maturidade, funÃ§Ãµes repetidas migram para `03_src/`, e os notebooks viram orquestradores.

---

### Diagrama de Arquitetura (CRISP-DM + Artefatos)

```mermaid
flowchart TB

A["00_data/00_raw - Dados originais"] --> B["00_data/01_bronze - IngestÃ£o mÃ­nima"]
B --> C["00_data/02_silver - Limpeza + consistÃªncia"]
C --> D["00_data/03_gold - ABT / Dataset de modelagem"]

subgraph Notebooks_CRISP_DM
N0["00_project_index - Hub + Gates"]
N1["01_business_data_understanding - BU + DU"]
N2["02_data_preparation_abt - Prep + FE + ABT"]
N3["03_modeling_validation - Modeling + Validation"]
N4["04_operationalization_submission - Deploy + Inference"]
end

D --> N3
N2 --> D

N1 --> AR1["artifacts/01 - EDA + Data Quality"]
N2 --> AR2["artifacts/02 - Features Manifest"]
N3 --> AR3["artifacts/03 - Benchmark + Validation"]
N4 --> AR4["artifacts/04 - Model Card"]

N3 --> M["models/best_model.pkl"]
M --> N4
N4 --> S["submissions/submission.csv"]

subgraph SRC_Evolution
S1["data_loader.py"]
S2["features.py"]
S3["modeling.py"]
S4["evaluation.py"]
end

S1 -.-> N1
S2 -.-> N2
S3 -.-> N3
S4 -.-> N4
```



### Diagrama (ASCII)

```textile
RAW â†’ BRONZE â†’ SILVER â†’ GOLD(ABT)  
|  
v  
Notebook 01 (BU+DU) â†’ artifacts/01 (EDA + Data Quality)  
Notebook 02 (Prep) â†’ artifacts/02 + gold/ABT  
Notebook 03 (Model) â†’ artifacts/03 + models/best_model.pkl  
Notebook 04 (Ops) â†’ artifacts/04 + submissions/submission.csv
```

EvoluÃ§Ã£o: lÃ³gica migra de notebooks â†’ src/ (data/features/model/eval)

---

# ğŸ” Fluxo de Trabalho

## ğŸ”¹ Notebook 00 â€” Project Index

Hub do projeto com:

- Links para fases

- Checklist (Gates)

- Registro de mÃ©tricas

---

## ğŸ”¹ Notebook 01 â€” Business + Data Understanding

EntregÃ¡veis:

- Problem Statement

- DefiniÃ§Ã£o de mÃ©tricas

- Baseline

- Data Quality Report

- Achados do EDA

Outputs:

```text
artifacts/01/
```

---

## ğŸ”¹ Notebook 02 â€” Data Preparation

EntregÃ¡veis:

- Feature Engineering

- ABT (Analytical Base Table)

- Manifest de features

Outputs:

```text
data/03_gold/abt_train.parquet
artifacts/02/features_manifest.json
```

---

## ğŸ”¹ Notebook 03 â€” Modeling + Validation

EntregÃ¡veis:

- Benchmark com Stratified CV

- GridSearch (quando aplicÃ¡vel)

- Escolha do modelo campeÃ£o

- ValidaÃ§Ã£o tÃ©cnica

Outputs:

```text
artifacts/03/benchmark.csv
models/best_model.pkl
```

---

## ğŸ”¹ Notebook 04 â€” Operationalization

EntregÃ¡veis:

- PersistÃªncia do modelo

- InferÃªncia

- Submission (Kaggle ou produÃ§Ã£o)

- Model Card

Outputs:

```text
models/best_model.pkl
submissions/submission.csv
artifacts/04/model_card.md
```

---

# âš™ï¸ ConfiguraÃ§Ã£o Central

Arquivo:

```text
artifacts/00_config/params.json
```

ContÃ©m:

- Target

- MÃ©trica principal

- Random state

- Caminhos padrÃ£o

- NÃºmero de folds CV

Isso garante consistÃªncia entre fases.

---

# ğŸ— Caminho Progressivo (EvoluÃ§Ã£o Recomendada)

### Fase 1 â€” Notebook-Only

Tudo implementado dentro dos notebooks.

### Fase 2 â€” ModularizaÃ§Ã£o Parcial

Mover funÃ§Ãµes repetidas para:

```text
03_src/
  data_loader.py
  features.py
  modeling.py
  evaluation.py
```

### Fase 3 â€” Arquitetura Profissional

- Notebooks tornam-se apenas orquestradores

- LÃ³gica principal vive em `src/`

- PreparaÃ§Ã£o para deploy real

---

# ğŸ“Š Quando Usar Este Template

- Projetos Kaggle

- Projetos de portfÃ³lio

- Casos simulados de negÃ³cio

- Provas tÃ©cnicas

- Projetos internos corporativos

---

# ğŸ§© Diferenciais

âœ” Estrutura clara e padronizada  
âœ” SeparaÃ§Ã£o entre dados e modelagem  
âœ” Gates por fase  
âœ” FÃ¡cil versionamento  
âœ” EscalÃ¡vel para produÃ§Ã£o  
âœ” Excelente narrativa para portfÃ³lio

---

# ğŸš€ Como Criar um Novo Projeto

1. Clique em **Use this template** no GitHub

2. Ajuste `params.json`

3. Coloque dados em `00_data/00_raw/`

4. Siga a ordem dos notebooks

---

# ğŸ“Œ PrÃ³ximos Passos Sugeridos

- Adicionar versionamento de experimentos

- Integrar com MLflow

- Criar CLI para rodar fases automaticamente

- Adicionar Docker

- Adicionar testes unitÃ¡rios no `src/`

---

## ğŸ¯ Why This Template Matters

This template demonstrates:

- Structured problem-solving using CRISP-DM

- Explicit artifact contracts between phases

- Reproducible environments (uv)

- Cross-over between Data Science and Data Engineering

- Progressive evolution from notebook to production-ready architecture

It reflects professional-level organization, scalability, and deployment awareness â€” not just model experimentation.

---

## ğŸ— Professional Positioning

This project is designed to simulate real-world data science delivery:

âœ” Clear phase separation  
âœ” Artifact versioning  
âœ” Validation rigor (Stratified CV + GridSearch)  
âœ” Model persistence and inference pipeline  
âœ” Scalable architecture ready for src/ evolution

# ğŸ‘¤ Autor

Roberto Soares  
Data Engineering | Data Science | Developer Experience

---
